{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "87175946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d2d6e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n",
      "32033\n"
     ]
    }
   ],
   "source": [
    "with open('names.txt','r') as h:\n",
    "    words = [w.rstrip() for w in h.readlines()]\n",
    "\n",
    "print(words[:8])\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b1116b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total characters: N=27\n",
      "\n",
      "{0: '.', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'} \n",
      "\n",
      "1\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(''.join(words)))\n",
    "chars = ['.']+chars\n",
    "\n",
    "#\n",
    "# same result as two rows above as '.' is less than any [a-z] or [0-9]\n",
    "#chars = sorted(set('.'.join(words)))\n",
    "\n",
    "# same:\n",
    "#chars = ['.']+[*chars]\n",
    "\n",
    "N = len(chars)\n",
    "print(f\"\\nTotal characters: {N=}\\n\")\n",
    "\n",
    "stoi = { s:i for i,s in enumerate(chars)}\n",
    "itos = { i:s for s,i in stoi.items()}\n",
    "\n",
    "print(itos,'\\n')\n",
    "\n",
    "encode = lambda c : stoi[c]\n",
    "decode = lambda i : itos[i]\n",
    "\n",
    "print(encode('a'))\n",
    "print(decode(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5bac0435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "block_size = 3\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = encode(ch)\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(decode(i) for i in context), '--->', decode(ix))\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fda784b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.Size([32, 3]), torch.int64, torch.Size([32]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype, X.shape, Y.dtype, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0db4e84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0],\n",
       "         [ 0,  0,  5],\n",
       "         [ 0,  5, 13],\n",
       "         [ 5, 13, 13],\n",
       "         [13, 13,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 15],\n",
       "         [ 0, 15, 12],\n",
       "         [15, 12,  9],\n",
       "         [12,  9, 22],\n",
       "         [ 9, 22,  9],\n",
       "         [22,  9,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  1],\n",
       "         [ 0,  1, 22],\n",
       "         [ 1, 22,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  9],\n",
       "         [ 0,  9, 19],\n",
       "         [ 9, 19,  1],\n",
       "         [19,  1,  2],\n",
       "         [ 1,  2,  5],\n",
       "         [ 2,  5, 12],\n",
       "         [ 5, 12, 12],\n",
       "         [12, 12,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 19],\n",
       "         [ 0, 19, 15],\n",
       "         [19, 15, 16],\n",
       "         [15, 16,  8],\n",
       "         [16,  8,  9],\n",
       "         [ 8,  9,  1]]),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "          1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8e3b3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "C = torch .randn(27, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "097ba593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6983519 -1.4097229]\n",
      "[0.17937961 1.895148  ] \n",
      "\n",
      "[[ 0.6983519  -1.4097229 ]\n",
      " [ 0.17937961  1.895148  ]] \n",
      "\n",
      "[[ 0.6983519  -1.4097229 ]\n",
      " [ 0.17937961  1.895148  ]]\n"
     ]
    }
   ],
   "source": [
    "print(C[5].numpy())\n",
    "print(C[6].numpy(), '\\n')\n",
    "print(C[[5,6]].numpy(), '\\n')\n",
    "print(C[torch.tensor([5,6])].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ac74d70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6984, -1.4097])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes = 27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "14870c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6984, -1.4097],\n",
      "        [ 0.1794,  1.8951]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack((C[5], C[6]), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8722c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T56s = torch.stack((C[5], C[6]), dim=0) \n",
    "T56 = C[[5,6]]\n",
    "print(torch.equal(T56,T56s))\n",
    "T56 == T56s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9378bf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3374, -0.1778],\n",
      "         [ 0.3374, -0.1778],\n",
      "         [ 0.6984, -1.4097]],\n",
      "\n",
      "        [[ 0.3374, -0.1778],\n",
      "         [ 0.6984, -1.4097],\n",
      "         [ 0.9666, -1.1481]]])\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# just index by tensor of indices!!! \n",
    "#\n",
    "print(C[X][[1,2]])\n",
    "# \n",
    "# that was just the first two rows of C[X] to keep it short\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a65b6340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n",
      "torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "print(C[X].shape)\n",
    "#\n",
    "# a bunch of 2-d vector embeddings indexed by X\n",
    "#\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bd870e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2c146663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.unbind(emb,1)) # torch.unbind(emb, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dee2d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "torch.Size([3, 4])\n",
      "(tensor([0, 1, 2, 3]), tensor([4, 5, 6, 7]), tensor([ 8,  9, 10, 11]))\n"
     ]
    }
   ],
   "source": [
    "xx = torch.tensor(range(12)).reshape(3,4)\n",
    "print(xx)\n",
    "print(xx.shape)\n",
    "print(torch.unbind(xx, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7f57c25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [35, 36, 37, 38, 39]],\n",
      "\n",
      "        [[40, 41, 42, 43, 44],\n",
      "         [45, 46, 47, 48, 49],\n",
      "         [50, 51, 52, 53, 54],\n",
      "         [55, 56, 57, 58, 59]]])\n",
      "torch.Size([3, 4, 5]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xx = torch.tensor(range(60)).reshape(3,4,5)\n",
    "print(xx)\n",
    "print(xx.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "20538dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [20, 21, 22, 23, 24],\n",
      "        [40, 41, 42, 43, 44]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.unbind(xx, dim=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b7d7ed95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [20, 21, 22, 23, 24],\n",
       "        [40, 41, 42, 43, 44]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "60f83fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6,  7,  8,  9],\n",
       "        [25, 26, 27, 28, 29],\n",
       "        [45, 46, 47, 48, 49]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unbind(xx, dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c8a90f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6,  7,  8,  9],\n",
       "        [25, 26, 27, 28, 29],\n",
       "        [45, 46, 47, 48, 49]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8b812407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# inefficient compared to view as cat will allocate new storage\n",
    "#\n",
    "torch.cat(torch.unbind(emb, dim=1), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "92292bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6,100))\n",
    "\n",
    "#\n",
    "# bias vector (1 per neuron)\n",
    "#\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "62eef3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3374, -0.1778,  0.3374, -0.1778,  0.3374, -0.1778],\n",
       "        [ 0.3374, -0.1778,  0.3374, -0.1778,  0.6984, -1.4097],\n",
       "        [ 0.3374, -0.1778,  0.6984, -1.4097,  0.9666, -1.1481],\n",
       "        [ 0.6984, -1.4097,  0.9666, -1.1481,  0.9666, -1.1481],\n",
       "        [ 0.9666, -1.1481,  0.9666, -1.1481, -0.3035, -0.5880],\n",
       "        [ 0.3374, -0.1778,  0.3374, -0.1778,  0.3374, -0.1778],\n",
       "        [ 0.3374, -0.1778,  0.3374, -0.1778, -0.6315, -2.8400],\n",
       "        [ 0.3374, -0.1778, -0.6315, -2.8400,  0.4965, -1.5723],\n",
       "        [-0.6315, -2.8400,  0.4965, -1.5723, -0.1690,  0.9178],\n",
       "        [ 0.4965, -1.5723, -0.1690,  0.9178,  1.3111, -0.2199],\n",
       "        [-0.1690,  0.9178,  1.3111, -0.2199, -0.1690,  0.9178],\n",
       "        [ 1.3111, -0.2199, -0.1690,  0.9178, -0.3035, -0.5880],\n",
       "        [ 0.3374, -0.1778,  0.3374, -0.1778,  0.3374, -0.1778],\n",
       "        [ 0.3374, -0.1778,  0.3374, -0.1778, -0.3035, -0.5880],\n",
       "        [ 0.3374, -0.1778, -0.3035, -0.5880,  1.3111, -0.2199],\n",
       "        [-0.3035, -0.5880,  1.3111, -0.2199, -0.3035, -0.5880],\n",
       "        [ 0.3374, -0.1778,  0.3374, -0.1778,  0.3374, -0.1778],\n",
       "        [ 0.3374, -0.1778,  0.3374, -0.1778, -0.1690,  0.9178],\n",
       "        [ 0.3374, -0.1778, -0.1690,  0.9178,  1.0533,  0.1388],\n",
       "        [-0.1690,  0.9178,  1.0533,  0.1388, -0.3035, -0.5880],\n",
       "        [ 1.0533,  0.1388, -0.3035, -0.5880,  0.3486,  0.6603],\n",
       "        [-0.3035, -0.5880,  0.3486,  0.6603,  0.6984, -1.4097],\n",
       "        [ 0.3486,  0.6603,  0.6984, -1.4097,  0.4965, -1.5723],\n",
       "        [ 0.6984, -1.4097,  0.4965, -1.5723,  0.4965, -1.5723],\n",
       "        [ 0.4965, -1.5723,  0.4965, -1.5723, -0.3035, -0.5880],\n",
       "        [ 0.3374, -0.1778,  0.3374, -0.1778,  0.3374, -0.1778],\n",
       "        [ 0.3374, -0.1778,  0.3374, -0.1778,  1.0533,  0.1388],\n",
       "        [ 0.3374, -0.1778,  1.0533,  0.1388, -0.6315, -2.8400],\n",
       "        [ 1.0533,  0.1388, -0.6315, -2.8400, -1.3250,  0.1784],\n",
       "        [-0.6315, -2.8400, -1.3250,  0.1784, -0.0770, -1.0205],\n",
       "        [-1.3250,  0.1784, -0.0770, -1.0205, -0.1690,  0.9178],\n",
       "        [-0.0770, -1.0205, -0.1690,  0.9178, -0.3035, -0.5880]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view((emb.shape[0],6))\n",
    "emb.view(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7f8f98cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view((emb.shape[0],6)) @ W1 + b1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "05b77605",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn(100,27)\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f705d93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2\n",
    "#\n",
    "#  number of samples times number of outcomes (27 letters)\n",
    "#\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bdf56a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# variant:\n",
    "#\n",
    "#counts1 = torch.exp(logits)\n",
    "counts = logits.exp()\n",
    "counts = counts/torch.sum(counts, dim=1, keepdim=True)\n",
    "print(counts.shape)\n",
    "print(counts[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9b17127c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.2853e-04, 1.7430e-11, 1.2537e-08, 9.1832e-10, 1.0705e-03, 1.4901e-06,\n",
       "        2.5817e-11, 1.1903e-07, 4.1851e-07, 3.1531e-17, 2.7315e-10, 4.5835e-09,\n",
       "        1.5925e-10, 4.1808e-06, 2.5429e-07, 6.8290e-02, 8.1018e-11, 6.5253e-05,\n",
       "        3.3588e-10, 4.7065e-04, 3.8369e-10, 3.2624e-21, 1.2444e-07, 5.5174e-08,\n",
       "        1.5604e-05, 1.6026e-04, 1.1157e-08, 3.3036e-08, 8.0063e-07, 4.7687e-11,\n",
       "        4.5782e-05, 1.5546e-10])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d5f1c1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9974e-01, 1.4941e-09])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#example of indexing:\n",
    "#\n",
    "counts[[1,2],[3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "734448ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17.7495)\n"
     ]
    }
   ],
   "source": [
    "loss = -counts[torch.arange(32), Y].log().mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "65891e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "C = torch.randn((N, 2), generator=g)\n",
    "\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "\n",
    "W2 = torch.randn((100, N), generator=g)\n",
    "b2 = torch.randn(N, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "05d39af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nsamples = 32\n",
      "\n",
      "totalParam = 3481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nsamples = len(Y)\n",
    "print(f\"\\n{nsamples = }\\n\")\n",
    "totalParam = sum(p.nelement() for p in parameters)\n",
    "print(f\"{totalParam = }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3e674e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss = tensor(17.7697, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# embed X into the embedding space\n",
    "emb = C[X]\n",
    "\n",
    "# layer 1 (hidden) \n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "#print(f\"{h.shape = }\")\n",
    "\n",
    "# output layer\n",
    "prob = F.softmax(h @ W2 + b2, dim=1)\n",
    "\n",
    "# log-loss\n",
    "loss = -prob[torch.arange(nsamples), Y].log().mean()\n",
    "print(f\"\\n{loss = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ac1573da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# More like the original:\n",
    "#\n",
    "# emb = C[X]\n",
    "# h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "# logits = h @ W2 + b2\n",
    "# counts = logits.exp()\n",
    "# prob = counts/torch.sum(counts, dim=1, keepdim=True)\n",
    "# nsamples = len(Y)\n",
    "# loss = -prob[torch.arange(nsamples), Y].log().mean()\n",
    "# print(f\"{loss = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "62ab9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = tensor(17.7697, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "print(f\"{loss = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b3dc8a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5213e-14, 1.2830e-12, 1.9647e-08, 3.1758e-10, 5.6763e-12, 1.0823e-10,\n",
       "        1.8821e-14, 1.1087e-08, 1.6134e-09, 2.1917e-03, 5.3863e-08, 3.1970e-04,\n",
       "        2.0283e-10, 3.5710e-11, 6.2336e-07, 5.1704e-07, 1.4206e-01, 9.5657e-09,\n",
       "        2.0670e-09, 2.5181e-02, 7.6846e-05, 2.8706e-12, 1.6961e-09, 5.6464e-15,\n",
       "        4.4656e-03, 2.6851e-09, 3.5864e-05, 2.3389e-04, 1.6890e-09, 9.5614e-01,\n",
       "        9.7404e-10, 2.1230e-12], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[torch.arange(nsamples), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "bc4f9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 17.76971435546875\n",
      "step = 30, loss = 0.6320147514343262\n",
      "step = 60, loss = 0.2750471830368042\n",
      "step = 90, loss = 0.27505427598953247\n",
      "step = 120, loss = 0.31967267394065857\n",
      "step = 150, loss = 1.8348438739776611\n",
      "step = 180, loss = 4.616419315338135\n",
      "step = 210, loss = 10.78406810760498\n",
      "step = 240, loss = 13.907838821411133\n",
      "step = 270, loss = 25.122119903564453\n",
      "loss = 45.83367156982422\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  Apparently not setting grad to None can cause divergence:\n",
    "#\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "C = torch.randn((N, 2), generator=g)\n",
    "\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "\n",
    "W2 = torch.randn((100, N), generator=g)\n",
    "b2 = torch.randn(N, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "Steps = 300\n",
    "for step in range(Steps):\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    \n",
    "#     for p in parameters:\n",
    "#         p.grad = None\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    if step % int(Steps/10) == 0:\n",
    "        print(f\"{step = }, loss = {loss.item()}\")\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data -= 0.1*p.grad\n",
    "\n",
    "print(f\"loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "62afc413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 17.76971435546875\n",
      "step = 30, loss = 1.1367990970611572\n",
      "step = 60, loss = 0.43213313817977905\n",
      "step = 90, loss = 0.34906232357025146\n",
      "step = 120, loss = 0.31282925605773926\n",
      "step = 150, loss = 0.29326295852661133\n",
      "step = 180, loss = 0.28327125310897827\n",
      "step = 210, loss = 0.2772060036659241\n",
      "step = 240, loss = 0.27310600876808167\n",
      "step = 270, loss = 0.2701391577720642\n",
      "loss = 0.2679549753665924\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "C = torch.randn((N, 2), generator=g)\n",
    "\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "\n",
    "W2 = torch.randn((100, N), generator=g)\n",
    "b2 = torch.randn(N, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "Steps = 300\n",
    "for step in range(Steps):\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    if step % int(Steps/10) == 0:\n",
    "        print(f\"{step = }, loss = {loss.item()}\")\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data -= 0.1*p.grad\n",
    "\n",
    "print(f\"loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "85b6d080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([12.2507, 15.6167, 19.7251, 19.2065, 15.1653, 12.2507, 14.5368, 12.9834,\n",
       "        14.6929, 16.7506, 14.3019, 19.3470, 12.2507, 15.2280, 15.6323, 18.4261,\n",
       "        12.2507, 15.1299, 13.3646, 15.2784, 17.2229, 14.2677,  9.4187,  9.3573,\n",
       "        14.6208, 12.2507, 14.8763, 15.4997, 11.8749, 15.2119, 17.4153, 14.0490],\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([19, 13, 13,  1,  0, 19, 12,  9, 22,  9,  1,  0, 19, 22,  1,  0, 19, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max value per row:\n",
    "logits.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d9d6b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
      "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([14,  0,  0,  0,  0,  4,  0,  0,  0,  0,  0,  0, 18,  0,  0,  0, 10,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y)\n",
    "torch.abs(Y-logits.max(dim=1).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f5beefea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n",
      "o\n",
      "a\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for ind in Y[torch.abs(Y-logits.max(dim=1).indices) > 0 ]:\n",
    "    print(decode(ind.item()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6b7a89a",
   "metadata": {},
   "source": [
    "emma\n",
    "... ---> e\n",
    "..e ---> m\n",
    ".em ---> m\n",
    "emm ---> a\n",
    "mma ---> .\n",
    "olivia\n",
    "... ---> o\n",
    "..o ---> l\n",
    ".ol ---> i\n",
    "oli ---> v\n",
    "liv ---> i\n",
    "ivi ---> a\n",
    "via ---> .\n",
    "ava\n",
    "... ---> a\n",
    "..a ---> v\n",
    ".av ---> a\n",
    "ava ---> .\n",
    "isabella\n",
    "... ---> i\n",
    "..i ---> s\n",
    ".is ---> a\n",
    "isa ---> b\n",
    "sab ---> e\n",
    "abe ---> l\n",
    "bel ---> l\n",
    "ell ---> a\n",
    "lla ---> .\n",
    "sophia\n",
    "... ---> s\n",
    "..s ---> o\n",
    ".so ---> p\n",
    "sop ---> h\n",
    "oph ---> i\n",
    "phi ---> a\n",
    "hia ---> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "758c3b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ---> a\n",
      "... ---> e\n",
      "... ---> i\n",
      "... ---> o\n",
      "... ---> s\n",
      "..a ---> v\n",
      "..e ---> m\n",
      "..i ---> s\n",
      "..o ---> l\n",
      "..s ---> o\n",
      ".av ---> a\n",
      ".em ---> m\n",
      ".is ---> a\n",
      ".ol ---> i\n",
      ".so ---> p\n",
      "abe ---> l\n",
      "ava ---> .\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "emm ---> a\n",
      "hia ---> .\n",
      "isa ---> b\n",
      "ivi ---> a\n",
      "liv ---> i\n",
      "lla ---> .\n",
      "mma ---> .\n",
      "oli ---> v\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "sab ---> e\n",
      "sop ---> h\n",
      "via ---> .\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Exploring ambiguity:\n",
    "#     sort by first 3 letters as this is our feature span\n",
    "#\n",
    "with open('ambiguous.txt','r') as h:\n",
    "    ambig = [line.rstrip() for line in  h.readlines()]\n",
    "\n",
    "ambig = sorted(ambig, key = lambda s: s[:3]+s[9])\n",
    "\n",
    "print(\"\\n\".join(ambig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "115b9b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.2874, -0.3045], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(0), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "953004d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  This is what is predicted for '...' input (instead of other (e,o,a,i) possibilities)\n",
    "#     this is why loss cannot become 0\n",
    "#     overfitting (exact prediction) otherwise\n",
    "#\n",
    "ind = torch.max(torch.tanh(C[[0,0,0]].view(-1,6) @ W1 + b1) @ W2 + b2, dim=1).indices\n",
    "print(decode(ind.item()))\n",
    "#\n",
    "#  This was just the forward pass calculation for '...', which is encoded as [0,0,0]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "893e1aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = torch.Size([228146, 3])\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "block_size = 3\n",
    "for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = encode(ch)\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "print(f\"{X.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "c0745d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem_size = torch.Size([228146, 3, 2])\n",
      "\n",
      "step = 0, loss = 19.505229949951172\n",
      "step = 2, loss = 15.776532173156738\n",
      "step = 4, loss = 14.002605438232422\n",
      "step = 6, loss = 12.57991886138916\n",
      "step = 8, loss = 11.47049331665039\n",
      "step = 10, loss = 10.709587097167969\n",
      "step = 12, loss = 10.127808570861816\n",
      "step = 14, loss = 9.614501953125\n",
      "step = 16, loss = 9.148944854736328\n",
      "step = 18, loss = 8.722230911254883\n",
      "loss = 8.521748542785645\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "C = torch.randn((N, 2), generator=g)\n",
    "\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "\n",
    "W2 = torch.randn((100, N), generator=g)\n",
    "b2 = torch.randn(N, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "Steps = 20\n",
    "\n",
    "problem_size = C[X].shape\n",
    "print(f\"{problem_size = }\\n\")\n",
    "\n",
    "for step in range(Steps):\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    if step % int(Steps/10) == 0:\n",
    "        print(f\"{step = }, loss = {loss.item()}\")\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data -= 0.1*p.grad\n",
    "\n",
    "print(f\"loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "8df48246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "    C = torch.randn((N, 2), generator=g)\n",
    "\n",
    "    W1 = torch.randn((6, 100), generator=g)\n",
    "    b1 = torch.randn(100, generator=g)\n",
    "\n",
    "    W2 = torch.randn((100, N), generator=g)\n",
    "    b2 = torch.randn(N, generator=g)\n",
    "\n",
    "    parameters = [C, W1, b1, W2, b2]\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b2a87730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem_size = torch.Size([32, 3, 2])\n",
      "\n",
      "step = 0, loss = 17.051074981689453\n",
      "step = 20, loss = 10.302067756652832\n",
      "step = 40, loss = 4.7621564865112305\n",
      "step = 60, loss = 3.713900089263916\n",
      "step = 80, loss = 3.8524434566497803\n",
      "step = 100, loss = 4.284707546234131\n",
      "step = 120, loss = 3.7801945209503174\n",
      "step = 140, loss = 3.2343482971191406\n",
      "step = 160, loss = 3.230024814605713\n",
      "step = 180, loss = 2.711892604827881\n",
      "loss = 2.8865065574645996\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  With minibatches\n",
    "#\n",
    "\n",
    "C, W1, b1, W2, b2 = parameters = model_init()\n",
    "\n",
    "Steps = 200\n",
    "\n",
    "ix = torch.randint(0, X.shape[0], (32,))\n",
    "problem_size = C[X[ix]].shape\n",
    "print(f\"{problem_size = }\\n\")\n",
    "\n",
    "for step in range(Steps):\n",
    "    \n",
    "    # assuming we have more than 32 samples, \n",
    "    # select a random set of indices of size 32:\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "    # this is done to increase speed as the gradient calculation \n",
    "    # is only done on the minibatch:\n",
    "    #\n",
    "    #  emb is much smaller (32x6), (32x3x2), actually\n",
    "    #\n",
    "    emb = C[X[ix]]    \n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y[ix])\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    if step % int(Steps/10) == 0:\n",
    "        print(f\"{step = }, loss = {loss.item()}\")\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data -= 0.1*p.grad\n",
    "    \n",
    "print(f\"loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "4ab74c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5583, -0.7779],\n",
       "         [ 0.2874, -0.0303],\n",
       "         [-1.5265,  1.0043]],\n",
       "\n",
       "        [[ 0.1102,  0.7698],\n",
       "         [-0.9867, -0.1947],\n",
       "         [-0.3284, -0.4330]]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[torch.tensor([[1,2,3],[4,5,6]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "5a06819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = torch.Size([228146, 3])\n",
      "X[0].shape = torch.Size([3])\n",
      "X[0] = tensor([0, 0, 0])\n",
      "C.shape = torch.Size([27, 2])\n",
      "C[X[0]] = tensor([[ 0.5077, -0.3840],\n",
      "        [ 0.5077, -0.3840],\n",
      "        [ 0.5077, -0.3840]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X.shape = }\")\n",
    "print(f\"{X[0].shape = }\")\n",
    "print(f\"{X[0] = }\")\n",
    "print(f\"{C.shape = }\")\n",
    "print(f\"{C[X[0]] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a17c1ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be9951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
